{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a rnn encoder decoder network for seq 2 seq\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 10, 26])\n"
     ]
    }
   ],
   "source": [
    "# to keep thing simple lets use one hot encoding representations for our sequential data\n",
    "# we are going to split the data X, Y\n",
    "data = [[\"i like to eat fish\", \"toi thit an ca\"],\n",
    "\t\t[\"have you ate yet\", \"co an com chua\"],\n",
    "\t\t[\"we are going to church tomorrow\", \"ngay may minh di le\"]]\n",
    "\n",
    "english = {}\n",
    "idx = 0\n",
    "for entry in data:\n",
    "\ttokens = entry[0].split(\" \")\n",
    "\tfor token in tokens:\n",
    "\n",
    "\t\tif token not in english:\n",
    "\t\t\tenglish[token] = idx\n",
    "\t\t\tidx += 1\n",
    "\n",
    "vietnamese = {}\n",
    "idx = 0\n",
    "for entry in data:\n",
    "\ttokens = entry[1].split(\" \")\n",
    "\tfor token in tokens:\n",
    "\n",
    "\t\tif token not in vietnamese:\n",
    "\t\t\tvietnamese[token] = idx\n",
    "\t\t\tidx += 1\n",
    "\n",
    "EMBEDDING_SIZE = 25\n",
    "MAX_SEQ_LEN = 10\n",
    "\n",
    "\n",
    "# NEED TO MODIFY THE BELOW TO GET THE SEQUENCE AND OHE FOR TEXT PER LANGUAGE\n",
    "input_data = []\n",
    "for entry in data:\n",
    "\tpair = []\n",
    "\tfor sentence in entry:\n",
    "\t\ttokens = sentence.split(\" \")\n",
    "\n",
    "\t\tsequence = []\n",
    "\t\tfor token in tokens:\n",
    "\t\t\tohe = [0]*EMBEDDING_SIZE\n",
    "\t\t\tohe[lexicon[token]] = 1\n",
    "\t\t\tsequence.append(ohe)\n",
    "\t\twhile len(sequence) < MAX_SEQ_LEN:\n",
    "\t\t\tohe = [0]*EMBEDDING_SIZE\n",
    "\t\t\tsequence.append(ohe)\n",
    "\n",
    "\t\tpair.append(sequence)\n",
    "\tinput_data.append(pair)\n",
    "\n",
    "data = torch.Tensor(input_data) # N, 2, L, Hin\n",
    "X = data[:, 0, :, :]\n",
    "Y = data[:, 1, :, :]\n",
    "print(X.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\tdef __init__(self, input_size, hidden_size, num_layers=1, bidirectional=False, batch_first=True):\n",
    "\t\tsuper(self, Encoder).__init__()\n",
    "\t\tself.rnn = nn.RNN(input_size=input_size,\n",
    "\t\t\t\t\thidden_size=hidden_size,\n",
    "\t\t\t\t\tnum_layers=num_layers,\n",
    "\t\t\t\t\tbidirectional=bidirectional,\n",
    "\t\t\t\t\tbatch_first=batch_first)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\toutput, hn = self.rnn(x)\n",
    "\t\treturn output, hn\n",
    "\n",
    "# check image on read me\n",
    "# if bidirectional = True\n",
    "# \taccording to torch LSTM doc, hn contains the final hidden states of forward and backward\n",
    "#\toutput contains the forward output and backward output at time step t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\tdef __init__(self, input_size, hidden_size, num_layers=1, bidirectional=False, batch_first=True):\n",
    "\t\tsuper(self, Decoder).__init__()\n",
    "\t\tself.rnn = nn.RNN(input_size=input_size,\n",
    "\t\t\t\t\thidden_size=hidden_size,\n",
    "\t\t\t\t\tnum_layers=num_layers,\n",
    "\t\t\t\t\tbidirectional=bidirectional,\n",
    "\t\t\t\t\tbatch_first=batch_first)\n",
    "\t\t\n",
    "\t\tself.linear = nn.Linear(hidden_size, EMBEDDING_SIZE) # note that "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
