{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a rnn encoder decoder network for seq 2 seq\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<SOS> i like to eat fish <EOS>', '<SOS> toi thit an ca <EOS>'], ['<SOS> have you ate yet <EOS>', '<SOS> co an com chua <EOS>'], ['<SOS> we are going to church tomorrow <EOS>', '<SOS> ngay may minh di le <EOS>']]\n"
     ]
    }
   ],
   "source": [
    "# to keep thing simple lets use one hot encoding representations for our sequential data\n",
    "# we are going to split the data X, Y\n",
    "data = [[\"i like to eat fish\", \"toi thit an ca\"],\n",
    "\t\t[\"have you ate yet\", \"co an com chua\"],\n",
    "\t\t[\"we are going to church tomorrow\", \"ngay may minh di le\"]]\n",
    "\n",
    "# also, most tokenizers add special tokens such as <SOS>, <EOS>, <SEP>, <MASK>, etc.\n",
    "# padding may be done as at this level as well\n",
    "data = [[\"<SOS> \"+sentence+\" <EOS>\"for sentence in entry] for entry in data]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 10, 25]) torch.Size([3, 10, 25])\n"
     ]
    }
   ],
   "source": [
    "english_dict = {}\n",
    "idx = 0\n",
    "for entry in data:\n",
    "\ttokens = entry[0].split(\" \")\n",
    "\tfor token in tokens:\n",
    "\n",
    "\t\tif token not in english_dict:\n",
    "\t\t\tenglish_dict[token] = idx\n",
    "\t\t\tidx += 1\n",
    "\n",
    "vietnamese_dict = {}\n",
    "idx = 0\n",
    "for entry in data:\n",
    "\ttokens = entry[1].split(\" \")\n",
    "\tfor token in tokens:\n",
    "\n",
    "\t\tif token not in vietnamese_dict:\n",
    "\t\t\tvietnamese_dict[token] = idx\n",
    "\t\t\tidx += 1\n",
    "\n",
    "EMBEDDING_SIZE = 25\n",
    "MAX_SEQ_LEN = 10\n",
    "\n",
    "english = []\n",
    "for entry in data:\n",
    "\tsentence = entry[0]\n",
    "\ttokens = sentence.split(\" \")\n",
    "\n",
    "\tsequence = []\n",
    "\tfor token in tokens:\n",
    "\t\tohe = [0]*EMBEDDING_SIZE\n",
    "\t\tohe[english_dict[token]] = 1\n",
    "\t\tsequence.append(ohe)\n",
    "\twhile len(sequence) < MAX_SEQ_LEN: # padding\n",
    "\t\tohe = [0]*EMBEDDING_SIZE\n",
    "\t\tsequence.append(ohe)\n",
    "\n",
    "\tenglish.append(sequence)\n",
    "\n",
    "vietnamese = []\n",
    "for entry in data:\n",
    "\tsentence = entry[1]\n",
    "\ttokens = sentence.split(\" \")\n",
    "\n",
    "\tsequence = []\n",
    "\tfor token in tokens:\n",
    "\t\tohe = [0]*EMBEDDING_SIZE\n",
    "\t\tohe[vietnamese_dict[token]] = 1\n",
    "\t\tsequence.append(ohe)\n",
    "\twhile len(sequence) < MAX_SEQ_LEN:\n",
    "\t\tohe = [0]*EMBEDDING_SIZE\n",
    "\t\tsequence.append(ohe)\n",
    "\n",
    "\tvietnamese.append(sequence)\n",
    "\n",
    "english = torch.Tensor(english)\n",
    "vietnamese = torch.Tensor(vietnamese)\n",
    "\n",
    "print(english.size(), vietnamese.size()) # batch size, sequence length, embedding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pytorch dataset and dataloader can be helpful\n",
    "class EN_VN_dataset(Dataset):\n",
    "\tdef __init__(self, params):\n",
    "\n",
    "\tdef __len__(self):\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\tdef __init__(self, input_size, hidden_size, num_layers=1, bidirectional=False, batch_first=True):\n",
    "\t\tsuper(Encoder, self).__init__()\n",
    "\t\tself.rnn = nn.RNN(input_size=input_size,\n",
    "\t\t\t\t\thidden_size=hidden_size,\n",
    "\t\t\t\t\tnum_layers=num_layers,\n",
    "\t\t\t\t\tbidirectional=bidirectional,\n",
    "\t\t\t\t\tbatch_first=batch_first)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\toutput, hn = self.rnn(x)\n",
    "\t\treturn output, hn\n",
    "\n",
    "# check image on read me\n",
    "# if bidirectional = True\n",
    "# \taccording to torch LSTM doc, hn contains the final hidden states of forward and backward\n",
    "#\toutput contains the forward output and backward output at time step t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\tdef __init__(self, input_size, hidden_size, num_layers=1, bidirectional=False, batch_first=True):\n",
    "\t\tsuper(Decoder, self).__init__()\n",
    "\t\tself.rnn = nn.RNN(input_size=input_size,\n",
    "\t\t\t\t\thidden_size=hidden_size,\n",
    "\t\t\t\t\tnum_layers=num_layers,\n",
    "\t\t\t\t\tbidirectional=bidirectional,\n",
    "\t\t\t\t\tbatch_first=batch_first) # common to have decoder architecture similar to encoder\n",
    "\t\t\n",
    "\t\tself.linear = nn.Linear(hidden_size, EMBEDDING_SIZE) # classificatin head\n",
    "\t\tself.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "\tdef forward(self, encoder_hidden):\n",
    "\t\tdecoder_hidden = encoder_hidden\n",
    "\n",
    "\t\t# we are going to unraveling the translation backwards\n",
    "\t\t# begin with the first input as <EOS>\n",
    "\t\tdecoder_input = []\n",
    "\t\tohe = [0]*EMBEDDING_SIZE\n",
    "\t\tohe[vietnamese_dict[\"<EOS>\"]] = 1\n",
    "\t\tdecoder_input.append([ohe]) # sequence length is one as we will step one at a time to change the input after each step\n",
    "\t\tdecoder_input = decoder_input*encoder_hidden.size(1)\n",
    "\t\tdecoder_input = torch.Tensor(decoder_input)\n",
    "\n",
    "\t\tdecoder_outputs = []\n",
    "\t\tfor step in range(MAX_SEQ_LEN):\n",
    "\t\t\tdecoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
    "\t\t\tdecoder_outputs.append(decoder_output)\n",
    "\t\t\t# use the output from the decoder as the input now\n",
    "\t\t\t_, topidx = decoder_output.topk(1) # the index of the highest value\n",
    "\t\t\ttopidx = topidx.squeeze(-1)\n",
    "\t\t\tdecoder_input = [] # create single sequence ohe for batch\n",
    "\t\t\tfor entry in topidx:\n",
    "\t\t\t\tohe = [0]*EMBEDDING_SIZE \n",
    "\t\t\t\tohe[entry.item()] = 1\n",
    "\t\t\t\tdecoder_input.append([ohe])\n",
    "\t\t\tdecoder_input = torch.Tensor(decoder_input).detach()\n",
    "\t\t\n",
    "\t\tdecoder_outputs = torch.stack(decoder_outputs, dim=1).squeeze(2) # reshaping data\n",
    "\t\tdecoder_outputs = self.softmax(decoder_outputs)\n",
    "\t\treturn decoder_outputs, decoder_hidden\n",
    "\n",
    "\tdef forward_step(self, x, hn):\n",
    "\t\t# function to run though rnn one step\n",
    "\t\tx, hn = self.rnn(x, hn)\n",
    "\t\tx = self.linear(x)\n",
    "\t\treturn x, hn\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(EMBEDDING_SIZE, 50)\n",
    "decoder = Decoder(EMBEDDING_SIZE, 50)\n",
    "encoder_output, encoder_hn = encoder(english)\n",
    "decoder_output, decoder_hn = decoder(encoder_hn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "param_groups = [\n",
    "    {'params': encoder.parameters(), 'lr': 0.0001},\n",
    "    {'params': decoder.parameters(), 'lr': 0.0001}\n",
    "]\n",
    "optimizer = optim.Adam(param_groups)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
